name: TOPS Measurement

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      quick_mode:
        description: 'Run quick benchmark'
        required: false
        default: true
        type: boolean

jobs:
  measure-tops:
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        include:
          - os: ubuntu-latest
            gpu: true
          - os: windows-latest
            gpu: true
    
    runs-on: ${{ matrix.os }}
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install torch torchvision numpy psutil py-cpuinfo pynvml

    - name: Install CUDA dependencies (Ubuntu)
      if: matrix.os == 'ubuntu-latest' && matrix.gpu
      run: |
        pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
    
    - name: Install CUDA dependencies (Windows)
      if: matrix.os == 'windows-latest' && matrix.gpu
      run: |
        pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
    
    - name: Measure TOPS
      run: |
        python scripts/tops_benchmark.py --output tops_${{ matrix.os }}.json ${{ github.event.inputs.quick_mode == 'true' && '--quick' || '' }}
    
    - name: Display Results
      run: |
        python -c "
        import json
        with open('tops_${{ matrix.os }}.json', 'r') as f:
            results = json.load(f)
        
        print('SYSTEM INFO FOR ${{ matrix.os }}:')
        sys_info = results.get('system_info', {})
        
        # CPU Info
        cpu = sys_info.get('cpu', {})
        print('CPU: ' + cpu.get('brand', 'Unknown'))
        print('Cores: ' + str(cpu.get('physical_cores', 'Unknown')) + ' physical, ' + str(cpu.get('logical_cores', 'Unknown')) + ' logical')
        
        # Memory Info
        memory = sys_info.get('memory', {})
        print('RAM: ' + str(memory.get('total_gb', 'Unknown')) + ' GB')
        
        # GPU Info
        gpu = sys_info.get('gpu', {})
        if gpu.get('detected_gpus'):
            for gpu_device in gpu['detected_gpus']:
                print('GPU: ' + gpu_device.get('name', 'Unknown') + ' (' + str(gpu_device.get('memory_gb', 'Unknown')) + ' GB)')
        elif gpu.get('pytorch_mps', {}).get('available'):
            print('GPU: Apple Silicon (MPS)')
        else:
            print('GPU: None detected')
        
        print()
        print('TOPS RESULTS:')
        print('Peak Performance: ' + str(round(results.get('peak_tops', 0), 2)) + ' TOPS')
        print('Average Performance: ' + str(round(results.get('average_tops', 0), 2)) + ' TOPS')
        print('Compute Device: ' + results.get('device', 'Unknown'))
        "
    
    - name: Upload TOPS results
      uses: actions/upload-artifact@v4
      with:
        name: tops-results-${{ matrix.os }}
        path: tops_${{ matrix.os }}.json
        retention-days: 30

  summary:
    needs: measure-tops
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Download all results
      uses: actions/download-artifact@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Generate TOPS Summary
      run: |
        python -c "
        import json
        import os
        import glob
        
        print('TOPS PERFORMANCE SUMMARY')
        print('=' * 50)
        
        results = {}
        for artifact_dir in glob.glob('tops-results-*'):
            os_name = artifact_dir.replace('tops-results-', '')
            json_file = os.path.join(artifact_dir, 'tops_' + os_name + '.json')
            if os.path.exists(json_file):
                with open(json_file, 'r') as f:
                    data = json.load(f)
                results[os_name] = data
        
        # Sort by peak performance
        sorted_results = sorted(results.items(), key=lambda x: x[1].get('peak_tops', 0), reverse=True)
        
        print('{:<15} | {:>10} | {:>10} | {:<12} | {:<30} | {:<25}'.format('', 'TOPS Peak', 'TOPS Avg', 'Device', 'CPU', 'GPU'))
        print('-' * 120)
        
        for os_name, data in sorted_results:
            peak = data.get('peak_tops', 0)
            avg = data.get('average_tops', 0)
            device = data.get('device', 'Unknown')
            
            # Get system info
            sys_info = data.get('system_info', {})
            cpu_brand = sys_info.get('cpu', {}).get('brand', 'Unknown')[:28]
            
            # Get GPU info
            gpu_info = sys_info.get('gpu', {})
            gpu_name = 'None'
            if gpu_info.get('detected_gpus'):
                gpu_name = gpu_info['detected_gpus'][0].get('name', 'GPU')[:23]
            elif gpu_info.get('pytorch_mps', {}).get('available'):
                gpu_name = 'Apple Silicon'
            
            print('{:<15} | {:>9.2f} | {:>9.2f} | {:<12} | {:<30} | {:<25}'.format(os_name, peak, avg, device, cpu_brand, gpu_name))
        
        # Find best performer
        if sorted_results:
            best_os, best_data = sorted_results[0]
            print('\\nBest Performer: ' + best_os + ' with ' + str(round(best_data.get('peak_tops', 0), 2)) + ' TOPS')
            
            # Show best system specs
            best_sys = best_data.get('system_info', {})
            best_cpu = best_sys.get('cpu', {}).get('brand', 'Unknown')
            best_gpu = 'None'
            if best_sys.get('gpu', {}).get('detected_gpus'):
                best_gpu = best_sys['gpu']['detected_gpus'][0].get('name', 'GPU')
            elif best_sys.get('gpu', {}).get('pytorch_mps', {}).get('available'):
                best_gpu = 'Apple Silicon'
            print('   CPU: ' + best_cpu)
            print('   GPU: ' + best_gpu)
        "
    
    - name: Comment PR with TOPS results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const glob = require('glob');
          
          let comment = '## TOPS Performance Results\\n\\n';
          comment += '| System | Peak TOPS | Average TOPS | Device | CPU | GPU |\\n';
          comment += '|--------|-----------|--------------|--------|-----|-----|\\n';
          
          const artifactDirs = glob.sync('tops-results-*');
          const results = [];
          
          for (const artifactDir of artifactDirs) {
            const osName = artifactDir.replace('tops-results-', '');
            const jsonFile = artifactDir + '/tops_' + osName + '.json';
            
            if (fs.existsSync(jsonFile)) {
              const data = JSON.parse(fs.readFileSync(jsonFile, 'utf8'));
              
              // Get system info
              const sysInfo = data.system_info || {};
              const cpuBrand = (sysInfo.cpu && sysInfo.cpu.brand || 'Unknown').substring(0, 20);
              
              let gpuName = 'None';
              if (sysInfo.gpu && sysInfo.gpu.detected_gpus && sysInfo.gpu.detected_gpus.length > 0) {
                gpuName = sysInfo.gpu.detected_gpus[0].name.substring(0, 15);
              } else if (sysInfo.gpu && sysInfo.gpu.pytorch_mps && sysInfo.gpu.pytorch_mps.available) {
                gpuName = 'Apple Silicon';
              }
              
              results.push({
                os: osName,
                peak: data.peak_tops || 0,
                avg: data.average_tops || 0,
                device: data.device || 'Unknown',
                cpu: cpuBrand,
                gpu: gpuName
              });
            }
          }
          
          // Sort by peak performance
          results.sort((a, b) => b.peak - a.peak);
          
          for (const result of results) {
            comment += '| ' + result.os + ' | ' + result.peak.toFixed(2) + ' | ' + result.avg.toFixed(2) + ' | ' + result.device + ' | ' + result.cpu + ' | ' + result.gpu + ' |\\n';
          }
          
          if (results.length > 0) {
            const best = results[0];
            comment += '\\n**Best Performer**: ' + best.os + ' with **' + best.peak.toFixed(2) + ' TOPS**\\n';
            comment += '- CPU: ' + best.cpu + '\\n';
            comment += '- GPU: ' + best.gpu + '\\n';
            comment += '- Device: ' + best.device;
          }
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });